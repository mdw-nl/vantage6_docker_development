application:
  # API key used to authenticate at the server.
  api_key: {{ V6_API_KEY_FILE | read_secret }}

  # URL of the vantage6 server
  server_url: {{ V6_SERVER_URL }}

  # port the server listens to
  port: {{ V6_SERVER_PORT }}

  # API path prefix that the server uses. Usually '/api' or an empty string
  api_path: {{ V6_API_PATH }}

  # subnet of the VPN server
  #vpn_subnet: 10.76.0.0/16

  # add additional environment variables to the algorithm containers.
  # this could be usefull for passwords or other things that algorithms
  # need to know about the node it is running on
  # OPTIONAL
  #algorithm_env:

    # in this example the environment variable 'player' has
    # the value 'Alice' inside the algorithm container
    #player: Alice

  # specify custom Docker images to use for starting the different
  # components.
  # OPTIONAL
  #images:
    #node: harbor2.vantage6.ai/infrastructure/node:petronas
    #alpine: harbor2.vantage6.ai/infrastructure/alpine
    #vpn_client: harbor2.vantage6.ai/infrastructure/vpn_client
    #network_config: harbor2.vantage6.ai/infrastructure/vpn_network

  # path or endpoint to the local data source. The client can request a
  # certain database by using its label. The type is used by the
  # auto_wrapper method used by algorithms. This way the algorithm wrapper
  # knows how to read the data from the source. The auto_wrapper currently
  # supports: 'csv', 'parquet', 'sql', 'sparql', 'excel', 'omop'. If your
  # algorithm does not use the wrapper and you have a different type of
  # data source you can specify 'other'.
  databases:
{% filter indent(4) %}
{% include 'databases.yaml.j2' %}
{% endfilter %}

  # end-to-end encryption settings
  encryption:
    # whenever encryption is enabled or not. This should be the same
    # as the `encrypted` setting of the collaboration to which this
    # node belongs.
    # TODO: SECURITY: Just a PoC for now, we'll get to encryption later
    enabled: False

    # location to the private key file
    # TODO: SECURITY: Just a PoC for now, we'll get to encryption later
    #private_key: /path/to/private_key.pem

  # Define who is allowed to run which algorithms on this node.
#  policies:
#    # Control which algorithm images are allowed to run on this node. This is
#    # expected to be a valid regular expression.
#    allowed_algorithms:
#      - ^harbor2.vantage6.ai/[a-zA-Z]+/[a-zA-Z]+
#    # Define which users are allowed to run algorithms on your node by their ID
#    allowed_users:
#      - 2
#    # Define which organizations are allowed to run images on your node by
#    # their ID or name
#    allowed_organizations:
#      - 6
#      - root

#  # credentials used to login to private Docker registries
#  docker_registries:
#    - registry: docker-registry.org
#      username: docker-registry-user
#      password: docker-registry-password
#
#  # Create SSH Tunnel to connect algorithms to external data sources. The
#  # `hostname` and `tunnel:bind:port` can be used by the algorithm
#  # container to connect to the external data source. This is the address
#  # you need to use in the `databases` section of the configuration file!
#  ssh-tunnels:
#
#    # Hostname to be used within the internal network. I.e. this is the
#    # hostname that the algorithm uses to connect to the data source. Make
#    # sure this is unique and the same as what you specified in the
#    # `databases` section of the configuration file.
#    - hostname: my-data-source
#
#      # SSH configuration of the remote machine
#      ssh:
#
#        # Hostname or ip of the remote machine, in case it is the docker
#        # host you can use `host.docker.internal` for Windows and MacOS.
#        # In the case of Linux you can use `172.17.0.1` (the ip of the
#        # docker bridge on the host)
#        host: host.docker.internal
#        port: 22
#
#        # fingerprint of the remote machine. This is used to verify the
#        # authenticity of the remote machine.
#        fingerprint: "ssh-rsa ..."
#
#        # Username and private key to use for authentication on the remote
#        # machine
#        identity:
#          username: username
#          key: /mnt/ssh/hostname.pem
#
#        # Once the SSH connection is established, a tunnel is created to
#        # forward traffic from the local machine to the remote machine.
#        tunnel:
#
#          # The port and ip on the tunnel container. The ip is always
#          # 0.0.0.0 as we want the algorithm container to be able to
#          # connect.
#          bind:
#            ip: 0.0.0.0
#            port: 8000
#
#          # The port and ip on the remote machine. If the data source runs
#          # on this machine, the ip most likely is 127.0.0.1.
#          dest:
#            ip: 127.0.0.1
#            port: 8000

  # Settings for the logger
  logging:
    # Controls the logging output level. Could be one of the following
    # levels: CRITICAL, ERROR, WARNING, INFO, DEBUG, NOTSET
    level:        DEBUG

    # Filename of the log-file, used by RotatingFileHandler
    file:         vnode.log

    # whenever the output needs to be shown in the console
    use_console:  true

    # The number of log files that are kept, used by RotatingFileHandler
    backup_count: 5

    # Size kb of a single log file, used by RotatingFileHandler
    max_size:     1024

    # format: input for logging.Formatter,
    format:       "%(asctime)s - %(name)-14s - %(levelname)-8s - %(message)s"
    datefmt:      "%Y-%m-%d %H:%M:%S"

  # directory where local task files (input/output) are stored
  # TODO: So is this ultimately read by v6? Or Just DATA_VOLUME_DATA ...?
  task_dir: {{ V6_NODE_DIR_DATA }}

  # Whether or not your node shares some configuration (e.g. which images are
  # allowed to run on your node) with the central server. This can be useful
  # for other organizations in your collaboration to understand why a task
  # is not completed. Obviously, no sensitive data is shared. Default true
  # TODO: I guess OK?
  share_config: true
